{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d4956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a055a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liste contenant les noms des colonnes de la Dataframe\n",
    "col_names = ['case_month','res_state', 'state_fips_code''res_county' ,'county_fips_code' ,'age_group' ,'sex' ,'race' ,'ethnicity','case_positive_specimen_interval' ,'case_onset_interval','process' ,'exposure_yn' ,'current_status','symptom_status','hosp_yn', 'icu_yn','death_yn' ,'underlying_conditions_yn' ]\n",
    "\n",
    "#Import des données\n",
    "df = pd.read_csv('CDC_Data_orig.csv', encoding='ISO-8859-1', header=0, names=col_names, index_col=None, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a313e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoder = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa53467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020-04    0\n",
       "2020-07    0\n",
       "2020-11    0\n",
       "2020-08    0\n",
       "2020-07    0\n",
       "          ..\n",
       "2020-11    0\n",
       "2020-06    0\n",
       "2020-10    0\n",
       "2020-06    0\n",
       "2020-07    0\n",
       "Name: death_yn, Length: 100, dtype: int32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#On encode les données pour que les modéles puis les traiter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for colonne in df.columns :\n",
    "    df_encoder[colonne] = le.fit_transform(df[colonne])\n",
    "    \n",
    "df_encoder['death_yn'].head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c39f08c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_month</th>\n",
       "      <th>res_state</th>\n",
       "      <th>state_fips_coderes_county</th>\n",
       "      <th>county_fips_code</th>\n",
       "      <th>age_group</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>case_positive_specimen_interval</th>\n",
       "      <th>case_onset_interval</th>\n",
       "      <th>process</th>\n",
       "      <th>exposure_yn</th>\n",
       "      <th>current_status</th>\n",
       "      <th>symptom_status</th>\n",
       "      <th>hosp_yn</th>\n",
       "      <th>icu_yn</th>\n",
       "      <th>death_yn</th>\n",
       "      <th>underlying_conditions_yn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>FORD</td>\n",
       "      <td>20057</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>WYANDOTTE</td>\n",
       "      <td>20209</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Contact tracing of case patient</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>HARVEY</td>\n",
       "      <td>20079</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Probable Case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>LYON</td>\n",
       "      <td>20111</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Routine surveillance</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>SALINE</td>\n",
       "      <td>20169</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Laboratory reported</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>WYANDOTTE</td>\n",
       "      <td>20209</td>\n",
       "      <td>0 - 17 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clinical evaluation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>CRAWFORD</td>\n",
       "      <td>20037</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Clinical evaluation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>SHAWNEE</td>\n",
       "      <td>20177</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Laboratory reported</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>SEWARD</td>\n",
       "      <td>20175</td>\n",
       "      <td>50 to 64 years</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Clinical evaluation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Probable Case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07</th>\n",
       "      <td>KS</td>\n",
       "      <td>20</td>\n",
       "      <td>SEDGWICK</td>\n",
       "      <td>20173</td>\n",
       "      <td>18 to 49 years</td>\n",
       "      <td>Male</td>\n",
       "      <td>Multiple/Other</td>\n",
       "      <td>Hispanic/Latino</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Multiple</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Laboratory-confirmed case</td>\n",
       "      <td>Symptomatic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        case_month  res_state state_fips_coderes_county  county_fips_code  \\\n",
       "2020-04         KS         20                      FORD             20057   \n",
       "2020-07         KS         20                 WYANDOTTE             20209   \n",
       "2020-11         KS         20                    HARVEY             20079   \n",
       "2020-08         KS         20                      LYON             20111   \n",
       "2020-07         KS         20                    SALINE             20169   \n",
       "...            ...        ...                       ...               ...   \n",
       "2020-11         KS         20                 WYANDOTTE             20209   \n",
       "2020-06         KS         20                  CRAWFORD             20037   \n",
       "2020-10         KS         20                   SHAWNEE             20177   \n",
       "2020-06         KS         20                    SEWARD             20175   \n",
       "2020-07         KS         20                  SEDGWICK             20173   \n",
       "\n",
       "              age_group     sex            race        ethnicity  \\\n",
       "2020-04  18 to 49 years    Male         Unknown  Hispanic/Latino   \n",
       "2020-07  18 to 49 years  Female         Unknown  Hispanic/Latino   \n",
       "2020-11  18 to 49 years    Male           White  Hispanic/Latino   \n",
       "2020-08  18 to 49 years  Female           White  Hispanic/Latino   \n",
       "2020-07  18 to 49 years    Male           White  Hispanic/Latino   \n",
       "...                 ...     ...             ...              ...   \n",
       "2020-11    0 - 17 years  Female           White  Hispanic/Latino   \n",
       "2020-06  18 to 49 years  Female           White  Hispanic/Latino   \n",
       "2020-10  18 to 49 years    Male           White  Hispanic/Latino   \n",
       "2020-06  50 to 64 years  Female           White  Hispanic/Latino   \n",
       "2020-07  18 to 49 years    Male  Multiple/Other  Hispanic/Latino   \n",
       "\n",
       "         case_positive_specimen_interval  case_onset_interval  \\\n",
       "2020-04                                0                    0   \n",
       "2020-07                                0                    0   \n",
       "2020-11                                1                    0   \n",
       "2020-08                                0                    0   \n",
       "2020-07                                0                    0   \n",
       "...                                  ...                  ...   \n",
       "2020-11                                0                    0   \n",
       "2020-06                                0                    0   \n",
       "2020-10                                1                    0   \n",
       "2020-06                                1                    0   \n",
       "2020-07                                0                    0   \n",
       "\n",
       "                                 process exposure_yn  \\\n",
       "2020-04                          Unknown     Unknown   \n",
       "2020-07  Contact tracing of case patient         Yes   \n",
       "2020-11                         Multiple         Yes   \n",
       "2020-08             Routine surveillance         Yes   \n",
       "2020-07              Laboratory reported     Unknown   \n",
       "...                                  ...         ...   \n",
       "2020-11              Clinical evaluation         Yes   \n",
       "2020-06              Clinical evaluation         Yes   \n",
       "2020-10              Laboratory reported         Yes   \n",
       "2020-06              Clinical evaluation         Yes   \n",
       "2020-07                         Multiple         Yes   \n",
       "\n",
       "                    current_status symptom_status hosp_yn   icu_yn death_yn  \\\n",
       "2020-04  Laboratory-confirmed case    Symptomatic      No       No       No   \n",
       "2020-07  Laboratory-confirmed case    Symptomatic      No       No       No   \n",
       "2020-11              Probable Case    Symptomatic      No       No       No   \n",
       "2020-08  Laboratory-confirmed case    Symptomatic      No       No       No   \n",
       "2020-07  Laboratory-confirmed case    Symptomatic      No  Unknown       No   \n",
       "...                            ...            ...     ...      ...      ...   \n",
       "2020-11  Laboratory-confirmed case    Symptomatic      No       No       No   \n",
       "2020-06  Laboratory-confirmed case    Symptomatic      No       No       No   \n",
       "2020-10  Laboratory-confirmed case    Symptomatic      No       No       No   \n",
       "2020-06              Probable Case    Symptomatic      No       No       No   \n",
       "2020-07  Laboratory-confirmed case    Symptomatic      No       No       No   \n",
       "\n",
       "        underlying_conditions_yn  \n",
       "2020-04                      Yes  \n",
       "2020-07                       No  \n",
       "2020-11                       No  \n",
       "2020-08                       No  \n",
       "2020-07                      Yes  \n",
       "...                          ...  \n",
       "2020-11                       No  \n",
       "2020-06                      Yes  \n",
       "2020-10                       No  \n",
       "2020-06                      Yes  \n",
       "2020-07                       No  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa18821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La fonction calcule le score ROC AUC\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        #création d'une liste de toutes les classes à l'exception de la classe actuelle \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #met la classe actuelle à 1 et les autres à 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #utilisation de la méthode sklearn metrics pour calculer le roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "    \n",
    "    check = pd.DataFrame(roc_auc_dict.items())\n",
    "    return np.mean(check)\n",
    "\n",
    "##########################  SVM Classifier  ################################\n",
    "def svm_fun(X_train,y_train,X_test,y_test):\n",
    "    #Création d'un classifeur SVM\n",
    "    clf = svm.SVC(kernel='linear')\n",
    "\n",
    "    #Entrainement du modele\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Prediction de la reponse avec le set de test\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    svm_acc = metrics.accuracy_score(y_test, y_pred)    \n",
    "    svm_prec = metrics.precision_score(y_test, y_pred,average='weighted') \n",
    "    svm_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "    svm_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')    \n",
    "    svm_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')   \n",
    "    svm_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix SVM : \\n\", confuse)\n",
    "    print(\"SVM Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    check = [svm_acc,svm_prec,svm_recall,svm_f1_weighted,svm_f1_macro,svm_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "    \n",
    "\n",
    "##########################  NB Classifier  ################################\n",
    "def gaus_nb_fun(X_train,y_train,X_test,y_test):\n",
    "    gnb = GaussianNB()\n",
    "    y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
    "    NB_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    NB_prec = metrics.precision_score(y_test, y_pred,average='weighted')    \n",
    "    NB_recall = metrics.recall_score(y_test, y_pred,average='weighted')\n",
    "    NB_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')\n",
    "    NB_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')\n",
    "    NB_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix NB : \\n\", confuse)\n",
    "    print(\"NB Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    check = [NB_acc,NB_prec,NB_recall,NB_f1_weighted,NB_f1_macro,NB_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "##########################  MLP Classifier  ################################\n",
    "def mlp_fun(X_train,y_train,X_test,y_test):\n",
    "    scaler = StandardScaler()  \n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)  \n",
    "    X_test_2 = scaler.transform(X_test)\n",
    "\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)  \n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred = mlp.predict(X_test_2)\n",
    "    \n",
    "    MLP_acc = metrics.accuracy_score(y_test, y_pred)    \n",
    "    MLP_prec = metrics.precision_score(y_test, y_pred,average='weighted') \n",
    "    MLP_recall = metrics.recall_score(y_test, y_pred,average='weighted')    \n",
    "    MLP_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')    \n",
    "    MLP_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')    \n",
    "    MLP_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix MLP : \\n\", confuse)\n",
    "    print(\"MLP Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')    \n",
    "    check = [MLP_acc,MLP_prec,MLP_recall,MLP_f1_weighted,MLP_f1_macro,MLP_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "##########################  knn Classifier  ################################\n",
    "def knn_fun(X_train,y_train,X_test,y_test):\n",
    "    classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    knn_acc = metrics.accuracy_score(y_test, y_pred)    \n",
    "    knn_prec = metrics.precision_score(y_test, y_pred,average='weighted')    \n",
    "    knn_recall = metrics.recall_score(y_test, y_pred,average='weighted')   \n",
    "    knn_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')   \n",
    "    knn_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')   \n",
    "    knn_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix KNN : \\n\", confuse)\n",
    "    print(\"KNN Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')  \n",
    "    check = [knn_acc,knn_prec,knn_recall,knn_f1_weighted,knn_f1_macro,knn_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "##########################  Random Forest Classifier  ################################\n",
    "def rf_fun(X_train,y_train,X_test,y_test):\n",
    "    # Import the model we are using\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    # Instanciation du model avec 1000 arbres de decision\n",
    "    rf = RandomForestClassifier(n_estimators = 100)\n",
    "    # Entrainement du modele\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    fr_acc = metrics.accuracy_score(y_test, y_pred)   \n",
    "    fr_prec = metrics.precision_score(y_test, y_pred,average='weighted')   \n",
    "    fr_recall = metrics.recall_score(y_test, y_pred,average='weighted')   \n",
    "    fr_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')  \n",
    "    fr_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')    \n",
    "    fr_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix RF : \\n\", confuse)\n",
    "    print(\"RF Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')   \n",
    "    check = [fr_acc,fr_prec,fr_recall,fr_f1_weighted,fr_f1_macro,fr_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "##########################  Logistic Regression Classifier  ################################\n",
    "def lr_fun(X_train,y_train,X_test,y_test):\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    LR_acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    LR_prec = metrics.precision_score(y_test, y_pred,average='weighted')    \n",
    "    LR_recall = metrics.recall_score(y_test, y_pred,average='weighted')    \n",
    "    LR_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')   \n",
    "    LR_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')   \n",
    "    LR_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix LR : \\n\", confuse)\n",
    "    print(\"LR Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')    \n",
    "    check = [LR_acc,LR_prec,LR_recall,LR_f1_weighted,LR_f1_macro,LR_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)\n",
    "\n",
    "\n",
    "def fun_decision_tree(X_train,y_train,X_test,y_test):\n",
    "    from sklearn import tree\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier()    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    dt_acc = metrics.accuracy_score(y_test, y_pred)    \n",
    "    dt_prec = metrics.precision_score(y_test, y_pred,average='weighted')    \n",
    "    dt_recall = metrics.recall_score(y_test, y_pred,average='weighted')    \n",
    "    dt_f1_weighted = metrics.f1_score(y_test, y_pred,average='weighted')    \n",
    "    dt_f1_macro = metrics.f1_score(y_test, y_pred,average='macro')    \n",
    "    dt_f1_micro = metrics.f1_score(y_test, y_pred,average='micro')\n",
    "    \n",
    "    confuse = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix DT : \\n\", confuse)\n",
    "    print(\"DT Class Wise Accuracy : \",confuse.diagonal()/confuse.sum(axis=1))\n",
    "    y_prob = y_pred\n",
    "    macro_roc_auc_ovo = roc_auc_score_multiclass(y_test, y_prob, average='macro')\n",
    "    \n",
    "    check = [dt_acc,dt_prec,dt_recall,dt_f1_weighted,dt_f1_macro,dt_f1_micro,macro_roc_auc_ovo[1]]\n",
    "    return(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8c571a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoder.drop(['death_yn'], axis=1).to_numpy()\n",
    "y = df_encoder['death_yn'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c76bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "#On sépare la base de données en train set et test set\n",
    "from sklearn.model_selection import ShuffleSplit # or StratifiedShuffleSplit\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04118bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67188, 17), (28796, 17))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4cc65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix NB : \n",
      " [[18027  6040  2753]\n",
      " [  171  1353    65]\n",
      " [   15    41   331]]\n",
      "NB Class Wise Accuracy :  [0.67214765 0.85147892 0.85529716]\n",
      "NB Time :  0.17420999999999953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akims\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix MLP : \n",
      " [[26207   561    52]\n",
      " [  818   771     0]\n",
      " [  308    17    62]]\n",
      "MLP Class Wise Accuracy :  [0.97714392 0.48521082 0.16020672]\n",
      "MLP Time :  43.6954417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akims\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3438: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn import svm\n",
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "svm_return = svm_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"SVM Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "svm_table.append(svm_return)\n",
    "     \n",
    "svm_table_final = pd.DataFrame(svm_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "gauu_nb_table_final = pd.DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = pd.DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = pd.DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = pd.DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = pd.DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = pd.DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328432c",
   "metadata": {},
   "source": [
    "Pour le NB, les scores sont sensiblements pareil mis à part pour \"Yes\" qui est supérieur de 0.27.\n",
    "\n",
    "Pour le MLP, les scores sont à peu prés pareil mis à part pour \"Unknown\" qui est inférieur à 0.38.\n",
    "\n",
    "Pour le KNN, les scores sont pareils à 0.06 prés.\n",
    "\n",
    "Pour le LR les scores sont pareils à 0.1 prés.\n",
    "\n",
    "Pour le DT, les scores sont à peu prés pareil mis à part pour \"Unknown\" qui est inférieur à 0.16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = pd.DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"SVM\",\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e4aae",
   "metadata": {},
   "source": [
    "Les scores sont du même ordre ici et dans l'étude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e93a0",
   "metadata": {},
   "source": [
    "## Boruta for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dab2761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.DataFrame(X)\n",
    "X_df.columns = [\"c1\",\"c2\",\"c3\",\"c4\",\"c5\",\"c6\",\"c7\",\"c8\",\"c9\",\"c10\",\"c11\",\"c12\",\"c13\",\"c14\",\"c15\",\"c16\",\"c17\"]\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cf6acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_shadow = X_df.apply(np.random.permutation)\n",
    "X_shadow.columns = ['shadow_' + feat for feat in X_df.columns]\n",
    "### make X_boruta by appending X_shadow to X\n",
    "X_boruta = pd.concat([X_df, X_shadow], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eef3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "### Entrain le modele random forest\n",
    "forest = RandomForestRegressor(max_depth = 5, random_state = 42)\n",
    "forest.fit(X_boruta, y)\n",
    "### Enregistrer les importances des caractéristiques\n",
    "feat_imp_X = forest.feature_importances_[:len(X_df.columns)]\n",
    "feat_imp_shadow = forest.feature_importances_[len(X_df.columns):]\n",
    "### calcule de hits hits\n",
    "hits = feat_imp_X > feat_imp_shadow.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68587f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55eb1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_tmp = []\n",
    "\n",
    "for i in range(len(hits)):\n",
    "    if(hits[i]==True):\n",
    "        indices_tmp.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a2a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_boruta_data = np.array(X_df.iloc[:,indices_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529bc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_boruta_data\n",
    "y = df_encoder['death_yn'].to_numpy()\n",
    "\n",
    "\n",
    "counter = 1\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit \n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3b129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "     \n",
    "gauu_nb_table_final = pd.DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = pd.DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = pd.DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = pd.DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = pd.DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = pd.DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c1587",
   "metadata": {},
   "source": [
    "Avec cette selection de feature, le score de l'accuracy ne bouge pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a095c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mean_mat = []\n",
    "\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = pd.DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6b4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pareil pour les autres metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ab4ea",
   "metadata": {},
   "source": [
    "## Ridge Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e87632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "X = df_encoder.drop(['death_yn'], axis=1).to_numpy()\n",
    "y = df_encoder['death_yn'].to_numpy()\n",
    "\n",
    "ridge_data = df_encoder.drop(['death_yn'], axis=1)\n",
    "                             \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    ridge_data,y,\n",
    "    test_size=0.3,\n",
    "    random_state=0)\n",
    "X_train.shape, X_test.shape\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))\n",
    "\n",
    "# L1 = Lasso, L2 = Ridge\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2', solver='liblinear'))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
    "\n",
    "sel_.get_support()\n",
    "\n",
    "selected_feat = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea73137",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.fillna(0))\n",
    "\n",
    "# L1 = Lasso, L2 = Ridge\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l2', solver='liblinear'))\n",
    "sel_.fit(scaler.transform(X_train.fillna(0)), y_train)\n",
    "\n",
    "sel_.get_support()\n",
    "\n",
    "selected_feat_ridge = X_train.columns[(sel_.get_support())]\n",
    "print('total features: {}'.format((X_train.shape[1])))\n",
    "print('selected features: {}'.format(len(selected_feat_ridge)))\n",
    "print('features with coefficients shrank to zero: {}'.format(\n",
    "      np.sum(sel_.estimator_.coef_ == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_Regression_data = sel_.transform(ridge_data.fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf1b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Ridge_Regression_data\n",
    "\n",
    "\n",
    "counter = 1\n",
    "svm_table = []\n",
    "gauu_nb_table = []\n",
    "mlp_table = []\n",
    "knn_table = []\n",
    "rf_table = []\n",
    "lr_table = []\n",
    "dt_table = []\n",
    "\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit \n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.3)\n",
    "sss.get_n_splits(X, y)\n",
    "train_index, test_index = next(sss.split(X, y)) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2227f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "start = timeit.default_timer()\n",
    "gauu_nb_return = gaus_nb_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"NB Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "mlp_return = mlp_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"MLP Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "knn_return = knn_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"KNN Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "rf_return = rf_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"RF Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "lr_return = lr_fun(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"LR Time : \", stop - start) \n",
    "\n",
    "start = timeit.default_timer()\n",
    "dt_return = fun_decision_tree(X_train,y_train,X_test,y_test)\n",
    "stop = timeit.default_timer()\n",
    "print(\"DT Time : \", stop - start) \n",
    "\n",
    "gauu_nb_table.append(gauu_nb_return)\n",
    "mlp_table.append(mlp_return)\n",
    "knn_table.append(knn_return)\n",
    "rf_table.append(rf_return)\n",
    "lr_table.append(lr_return)\n",
    "dt_table.append(dt_return)\n",
    "# svm_table.append(svm_return)\n",
    "\n",
    "gauu_nb_table_final = pd.DataFrame(gauu_nb_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "mlp_table_final = pd.DataFrame(mlp_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "knn_table_final = pd.DataFrame(knn_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "rf_table_final = pd.DataFrame(rf_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "lr_table_final = pd.DataFrame(lr_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])\n",
    "\n",
    "dt_table_final = pd.DataFrame(dt_table, columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd991eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking average of all k-fold performance values\n",
    "final_mean_mat = []\n",
    "\n",
    "# final_mean_mat.append(np.transpose((list(svm_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(gauu_nb_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(mlp_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(knn_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(rf_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(lr_table_final.mean()))))\n",
    "final_mean_mat.append(np.transpose((list(dt_table_final.mean()))))\n",
    "\n",
    "final_avg_mat = pd.DataFrame(final_mean_mat,columns=[\"Accuracy\",\"Precision\",\"Recall\",\n",
    "                                                \"F1 (weighted)\",\"F1 (Macro)\",\"F1 (Micro)\",\"ROC AUC\"], \n",
    "                          index=[\"NB\",\"MLP\",\"KNN\",\"RF\",\"LR\",\"DT\"])\n",
    "\n",
    "final_avg_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbec590",
   "metadata": {},
   "source": [
    "Pour le NB, accuracy, recall, F1 (weighted) meilleur de 0.1 et un moins bon ROC.\n",
    "\n",
    "Pour le reste c'est à peu prés pareil si ce n'est \"F1 (Macro)\" qui est inférieur de 0.1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
